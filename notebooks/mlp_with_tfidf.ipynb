{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ZTqxdzn7RW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_kazakh_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zа-яәғқңөүұһі0-9\\s]', ' ', text)  # keep Kazakh alphabet\n",
        "    text = re.sub(r'\\d+', ' ', text)                      # remove numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "dgfjqRoSuGCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/merged.csv\")\n",
        "df['label'] = df['label'].str.upper()\n",
        "df = df[df['label'].str.lower() != 'label']\n",
        "df = df.dropna(subset=[\"text\", \"label\"])\n",
        "\n",
        "df[\"clean\"] = df[\"text\"].apply(clean_kazakh_text)\n"
      ],
      "metadata": {
        "id": "humSZhbluHn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_counts = df[\"label\"].value_counts()\n",
        "print(\"\\nLabel counts:\")\n",
        "print(label_counts)\n",
        "\n",
        "print(\"\\nLabel proportions:\")\n",
        "print((label_counts / len(df)).round(3))\n",
        "\n",
        "# Imbalance ratio (max_count / min_count)\n",
        "imbalance_ratio = label_counts.max() / label_counts.min()\n",
        "print(f\"\\nImbalance ratio (max/min): {imbalance_ratio:.2f}\")\n",
        "\n",
        "# Comment length statistics\n",
        "df[\"text_len\"] = df[\"text\"].astype(str).apply(lambda x: len(x.split()))\n",
        "print(\"\\nText length stats (in tokens):\")\n",
        "print(df[\"text_len\"].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTbH9qY-GfK3",
        "outputId": "7a100e5f-42ca-41c8-a0c5-92e03a9d0c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label counts:\n",
            "label\n",
            "NORMAL         1052\n",
            "HATE_SPEECH     498\n",
            "OFFENSIVE       396\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label proportions:\n",
            "label\n",
            "NORMAL         0.541\n",
            "HATE_SPEECH    0.256\n",
            "OFFENSIVE      0.203\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Imbalance ratio (max/min): 2.66\n",
            "\n",
            "Text length stats (in tokens):\n",
            "count    1946.000000\n",
            "mean        9.843782\n",
            "std        11.683234\n",
            "min         1.000000\n",
            "25%         4.000000\n",
            "50%         7.000000\n",
            "75%        11.000000\n",
            "max       201.000000\n",
            "Name: text_len, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=30000,\n",
        "    ngram_range=(1,2),\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(df[\"clean\"]).toarray()\n"
      ],
      "metadata": {
        "id": "K85rg1wUuMOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\"NORMAL\": 0, \"OFFENSIVE\": 1, \"HATE_SPEECH\": 2}\n",
        "y = df[\"label\"].map(labels_map).values\n"
      ],
      "metadata": {
        "id": "gRrUDcU8uN7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "M2-xSLQRuPcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TfidfDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.X = torch.tensor(features, dtype=torch.float32)\n",
        "        self.y = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "sOi2aB5NuRai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(TfidfDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(TfidfDataset(X_test, y_test),  batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "JoJ8UkvQuUJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1=256, hidden2=128, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(hidden1, hidden2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(hidden2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "x-AcYmVAuVZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MLPClassifier(input_dim=X_train.shape[1]).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "nEGW4NKVuX0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL_-O1ooFlA6",
        "outputId": "78a6d30f-3362-492b-8622-c78dda40d5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Loss: 26.660\n",
            "Epoch 2/50 - Loss: 21.547\n",
            "Epoch 3/50 - Loss: 14.564\n",
            "Epoch 4/50 - Loss: 8.388\n",
            "Epoch 5/50 - Loss: 2.125\n",
            "Epoch 6/50 - Loss: 0.387\n",
            "Epoch 7/50 - Loss: 0.240\n",
            "Epoch 8/50 - Loss: 0.129\n",
            "Epoch 9/50 - Loss: 0.125\n",
            "Epoch 10/50 - Loss: 0.104\n",
            "Epoch 11/50 - Loss: 0.118\n",
            "Epoch 12/50 - Loss: 0.105\n",
            "Epoch 13/50 - Loss: 0.114\n",
            "Epoch 14/50 - Loss: 0.098\n",
            "Epoch 15/50 - Loss: 0.107\n",
            "Epoch 16/50 - Loss: 0.087\n",
            "Epoch 17/50 - Loss: 0.084\n",
            "Epoch 18/50 - Loss: 0.062\n",
            "Epoch 19/50 - Loss: 0.066\n",
            "Epoch 20/50 - Loss: 0.088\n",
            "Epoch 21/50 - Loss: 0.114\n",
            "Epoch 22/50 - Loss: 0.086\n",
            "Epoch 23/50 - Loss: 0.092\n",
            "Epoch 24/50 - Loss: 0.095\n",
            "Epoch 25/50 - Loss: 0.064\n",
            "Epoch 26/50 - Loss: 0.074\n",
            "Epoch 27/50 - Loss: 0.087\n",
            "Epoch 28/50 - Loss: 0.074\n",
            "Epoch 29/50 - Loss: 0.086\n",
            "Epoch 30/50 - Loss: 0.081\n",
            "Epoch 31/50 - Loss: 0.093\n",
            "Epoch 32/50 - Loss: 0.087\n",
            "Epoch 33/50 - Loss: 0.074\n",
            "Epoch 34/50 - Loss: 0.085\n",
            "Epoch 35/50 - Loss: 0.062\n",
            "Epoch 36/50 - Loss: 0.072\n",
            "Epoch 37/50 - Loss: 0.066\n",
            "Epoch 38/50 - Loss: 0.096\n",
            "Epoch 39/50 - Loss: 0.063\n",
            "Epoch 40/50 - Loss: 0.082\n",
            "Epoch 41/50 - Loss: 0.083\n",
            "Epoch 42/50 - Loss: 0.082\n",
            "Epoch 43/50 - Loss: 0.097\n",
            "Epoch 44/50 - Loss: 0.073\n",
            "Epoch 45/50 - Loss: 0.071\n",
            "Epoch 46/50 - Loss: 0.064\n",
            "Epoch 47/50 - Loss: 0.064\n",
            "Epoch 48/50 - Loss: 0.095\n",
            "Epoch 49/50 - Loss: 0.078\n",
            "Epoch 50/50 - Loss: 0.062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        outputs = model(batch_x)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(batch_y.numpy())\n"
      ],
      "metadata": {
        "id": "CpqRa5vjFm5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    all_labels, all_preds, average=\"weighted\"\n",
        ")\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(\"\\nEvaluation:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33F2TWCuFqvD",
        "outputId": "30a7cf0b-af77-4540-fd52-dddd257b4b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation:\n",
            "Accuracy:  0.7949\n",
            "Precision: 0.8193\n",
            "Recall:    0.7949\n",
            "F1 Score:  0.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# reverse mapping (numeric → label)\n",
        "inv_label_map = {0: \"NORMAL\", 1: \"OFFENSIVE\", 2: \"HATE_SPEECH\"}\n",
        "\n",
        "# convert numeric preds → label names\n",
        "pred_names = [inv_label_map[p] for p in all_preds]\n",
        "true_names = [inv_label_map[t] for t in all_labels]\n",
        "\n",
        "print(\"\\nFinal evaluation on validation set (best epoch metrics above):\\n\")\n",
        "\n",
        "print(classification_report(\n",
        "    true_names,\n",
        "    pred_names,\n",
        "    digits=2\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL5rCXpfHju9",
        "outputId": "b0171158-65b1-4466-cfdb-125eb07d9f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final evaluation on validation set (best epoch metrics above):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " HATE_SPEECH       0.81      0.78      0.80       100\n",
            "      NORMAL       0.77      0.95      0.85       211\n",
            "   OFFENSIVE       0.97      0.41      0.57        79\n",
            "\n",
            "    accuracy                           0.79       390\n",
            "   macro avg       0.85      0.71      0.74       390\n",
            "weighted avg       0.82      0.79      0.78       390\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"kazakh_toxicity_mlp.pt\")\n",
        "\n",
        "import joblib\n",
        "joblib.dump(vectorizer, \"kazakh_vectorizer.pkl\")\n",
        "\n",
        "print(\"Model & vectorizer saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3Zv0JyFsOp",
        "outputId": "69bdccb9-7ac0-4bd6-caed-52a29d291a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model & vectorizer saved.\n"
          ]
        }
      ]
    }
  ]
}